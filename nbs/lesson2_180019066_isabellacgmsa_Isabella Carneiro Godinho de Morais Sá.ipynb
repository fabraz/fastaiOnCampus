{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Reconhecimento de flores e árvores\n\n## Autora\n* Isabella Carneiro Godinho de Morais Sá\n* Matrícula: 18/0019066\n* Github: isabellacgmsa\n\n## Objetivo\nO propósito do presente artigo é demonstrar o conhecimento adquirido através da segunda lição, que ensina a usar matriz de confusão, ImageClassifierCleaner e deploy.\n\n## Dependências\n\nA instalação das dependências é um passo fundamental para garantir que o processo possa ser executado com sucesso e que os resultados sejam precisos e confiáveis. Além disso, a escolha das bibliotecas e ferramentas adequadas é essencial para garantir que o processo seja executado de maneira eficiente e eficaz, maximizando os recursos disponíveis e minimizando o tempo necessário para a execução do processo.\nAssim sendo, o primeiro passo que foi tomado para iniciar o projeto foi a instalação das dependências necessárias para que o processo pudesse ser executado de maneira adequada.\nPara tanto, foram utilizados os seguintes comandos para a instalação das dependências necessárias:\n\n```pip install -U duckduckgo_search```\n\n```pip install fastai\"```\n\nVale ressaltar que, antes de iniciar o processo, é necessário fazer a instalação do PyTorch, que é uma biblioteca de aprendizado de máquina de código aberto amplamente utilizada para tarefas como visão computacional e processamento de linguagem natural.\n\n## Baixando imagens\nPara fazer a instalação das imagens foi utilizado o ddg_images, como mostra o código a seguir:  \n```\nfrom duckduckgo_search import ddg_images\nfrom fastcore.all import *\n\ndef search_images(term: str, max_images=30):\n    print(f\"Searching for '{term}'\")\n    return L(ddg_images(term, max_results=max_images)).itemgot('image')\n    \n```\n\nO primeiro teste será feito baixando apenas uma imagem de flor:\n\n```\nurls = search_images('flower', max_images=1)\nurls[2]\n```\n\nO download será realizado utilizando a biblioteca fastdownload:\n\n```\nfrom fastdownload import download_url\ndest = 'oneflower.jpg'\ndownload_url(urls[0], dest, show_progress=False)\n\nfrom fastai.vision.all import *\nim = Image.open(dest)\nim.to_thumb(256,256)\n```\n\n![texto](https://s3.static.brasilescola.uol.com.br/be/2020/12/girassol.jpg)\n\nAo constatar que está funcionando todo o processo é possível fazer o download de dados mais numerosos:\n```\nsearches = 'tree', 'flower'\npath = Path('tree_flower')\nfrom time import sleep\n\nfor o in searches:\n    dest = (path/o)\n    dest.mkdir(exist_ok=True, parents=True)\n    download_images(dest, urls=search_images(f'{o} tree'))\n    sleep(10)\n    download_images(dest, urls=search_images(f'{o} flower'))\n    sleep(10)\n    resize_images(path/o, max_size=400, dest= path/o)\n```\n\nFoi utilizado o sleep para que não haja problemas no tráfego de informações.\n\nEssas imagens serão salvas em uma pasta cujo caminho está definido no path.\n\n## Treinamento\n### Passo 1\nAntes de iniciar o treinamento do modelo de fato é necessário garantir que não haja imagens com erro para evitar futuros problemas:\n\n```\nfailed = verify_images(get_image_files(path))\nfailed.map(Path.unlink)\nlen(failed)\n```\n### Passo 2\n\nPara treinar modelos de aprendizado de máquina com conjuntos de dados volumosos, é necessário dividir os dados em lotes menores para evitar sobrecarregar a memória RAM do computador. O Dataloader é uma classe que oferece essa funcionalidade de forma eficiente. Ele carrega e processa os dados em lotes menores, tornando o processo de treinamento escalável.\n\nO fastai é um framework de aprendizado de máquina que permite o uso do datablock, uma ferramenta que facilita a personalização do processamento e organização dos dados em lotes para treinamento do modelo. Com o datablock, é possível definir etapas como leitura, pré-processamento e organização dos dados de forma mais simples. Isso permite que os usuários criem fluxos de trabalho personalizados e experimentem diferentes abordagens para melhorar a precisão do modelo.\n\n```\ndls = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=[Resize(192, method='squish')]\n).dataloaders(path, bs=32)\n\ndls.show_batch(max_n=6)\n```\n![texto](https://i.ibb.co/T4XzYk1/flores.png)\n\nFoi especificado que há o ImageBlock, que é uma classe do fastai que permite a criação de blocos para processar as imagens no modelo, e o CategoryBlock que cria blocos para processar variáveis categóricas, nesse caso árvore ou flor. Nesse trecho também especifica o tamanho que as imagens terão, já que precisa ser o mesmo para todas.\n\n### Passo 3\nApós criar o Datablock, o modelo é treinado com a ajuda do objeto \"Learner\". Ele é configurado com três argumentos: o primeiro é um DataLoader (dls) que contém o conjunto de dados de treinamento do modelo; o segundo é a arquitetura ResNet18 que será usada como base para o modelo; e o terceiro é a métrica usada para avaliar a performance do modelo, que neste caso é a taxa de erro.\n\nPara realizar o ajuste fino do modelo, é utilizado o método \"fine_tune()\". Esse método realiza um treinamento adicional do modelo usando os pesos pré-treinados da ResNet18 como ponto de partida.\n```\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(8)\n```\n\n### Passo 4\nUtilizaremos a matriz de confusão, que é uma ferramenta muito utilizada em aprendizado de máquina para avaliar o desempenho de um modelo. Ela apresenta a frequência de acertos e erros do modelo em relação às classes que estão sendo avaliadas.\nCom ela é possível obter diversas métricas importantes, como a acurácia, a precisão, o recall, a taxa de falsos positivos e a taxa de falsos negativos. Com base nessas métricas, é possível avaliar o desempenho do modelo e fazer ajustes que permitam melhorar sua precisão e acurácia.\n\n```\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()\n```\n![imagem](https://i.ibb.co/Xj1W9cs/matriz.png)\n\n### Passo 5\nFoi utilizada também a função plot_top_losses para identificar as imagens que mais contribuem para o erro de um modelo. Essa função retorna as imagens que apresentam os maiores valores de erro em relação ao valor de loss calculado para cada uma das imagens em um conjunto de dados.\n\nAo analisar as imagens que apresentam os maiores valores de erro, é possível identificar padrões e características que podem estar contribuindo para a performance insatisfatória do modelo, possibilitando ajustes e melhorias. Além disso, a análise dessas imagens também pode ajudar a identificar erros na rotulagem dos dados, que podem estar comprometendo a acurácia do modelo.\n\nA utilização da função plot_top_losses é uma etapa importante no processo de avaliação e ajuste de um modelo de aprendizado de máquina. A partir da identificação das imagens que mais contribuem para o erro, é possível fazer ajustes que permitam melhorar a precisão e a acurácia do modelo, tornando-o mais confiável e eficaz.\n\n```\ninterp.plot_top_losses(5, nrows=1)\n\n```\n\n![image](https://i.ibb.co/vZRBStK/download.png)\n\n\n### Passo 6\nPara garantir a acurácia das imagens testadas usa-se o ImageClassifierCleaner que permite a remoção de imagens incorretamente rotuladas em um conjunto de dados de treinamento.\n\n```\ncleaner = ImageClassifierCleaner(learn)\ncleaner\n```\n\nUsamos o seguinte código para remover imagens incorretas e reorganizar as imagens corretamente rotuladas em um diretório específico, facilitando assim o processo de limpeza e preparação dos dados para o treinamento do modelo de aprendizado de máquina.\n\n```\nfor idx in cleaner.delete(): cleaner.fns[idx].unlink()\nfor idx,cat in cleaner.change(): shutil.move(str(cleaner.fns[idx]), path/cat)\n```\n\n### Passo 7\nPara realizar o deploy utiliza-se a função export para criar um arquivo com todas as informações e configurações necessárias:\n\n```\nlearn.export('model.pkl')\n```\n\nO deploy é realizado utilizando um space na Hugging Face criando um commit do arquivo que foi gerado:\n\n![imagem](https://i.ibb.co/7Kg6Scm/download-1.png)\n\n\n## Conclusão\nEm conclusão, o desenvolvimento e deploy de um modelo de aprendizado de máquina capaz de identificar flores e árvores é um processo complexo, que envolve várias etapas, desde a preparação e limpeza dos dados, passando pela escolha do modelo e dos parâmetros, até a avaliação e ajuste do modelo.\nO Hugging Face é simples de entender como subir o modelo e o fastai possui várias ferramentas que auxiliam e deixam mais simples desenvolver.\nHá alguns ajustes a serem feitos no modelo para reduzir erros e, consequentemente, aumentar sua acurácia.\n\n\n\n",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      }
    }
  ]
}